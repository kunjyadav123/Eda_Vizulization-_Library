{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMPLETE PANDAS FOR DATA SCIENCE : (VENV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.4\n",
      "2.2.3\n",
      "3.1.5\n"
     ]
    }
   ],
   "source": [
    "import numpy as np  \n",
    "import pandas as pd\n",
    "import openpyxl as opy\n",
    "\n",
    "print(np.__version__)\n",
    "print(pd.__version__)\n",
    "print(opy.__version__)\n",
    "\n",
    "# Importing modeules of numpy and pandas ! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA UNDERSTANDING : VIA READING DATA \n",
    "# We may read data by two methods .\n",
    "\n",
    "# 1 Way : Read existing data in csv file , excel fie , json data sql file etc.\n",
    "# 2 Way : Create a file of data then read it\n",
    "\n",
    "# lets see first way.\n",
    "\n",
    "# Note : Be super comfortable with syntax to read file especilllay reading existing files , be aware about system  and syntax of difereenet different file extension(csv ,excel, json and sql etc.) how the works and used.\n",
    "# Note : Intially Things might be challenging and complex but just stick to it and keep practicing every thing willl be sorted.\n",
    "# Note: Get aware about how and when encoding and of which encoding is required .\n",
    "# Note : Be aware out all modules required(if required) to make read a file of some specific file . e.g to read xlsx file we required xlrd module , khair abhi to install kr liya hai.\n",
    "# Get comfortable about ecosystem of dataframes and how they works in pandas and be ready with what is requires.\n",
    "\n",
    "# By the way encoding invoke is required for .json and .csv only and it is latin1 and no module intallation is required for them , for .xlsx no invoking of encoding is required but the module intsallation of xlrd is neccessary.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Note : For specific extension type we need to invoke  that specific encoding practice only one time after that it willl get invoke by its own for that extension type.\n",
    "# FOR .CSV AND .JSON  eccoding practices is latin1. and  no modeule installation.\n",
    "# FOR .xlsx no encoding is required but module of xlrd is required to install.\n",
    "# dont forget to put that starting   r \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding/Overview of file handling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Reading existing file.\n",
    "#### Supppoted format in Pandas : CSV , EXCEL , JSON , SQL etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FOR READING EXISTING DATA OF FILE PANDAS PROVIDERS US VARIOUS READING (FUNCTIONS/METHODS) TO MAKE IT LOAD INTO PANDAS DATAFRAMES.\n",
    "\n",
    "# FOR .csv  : pd.read_csv(file_name)\n",
    "# FOR .json : pd.read_json(file_name)\n",
    "# FOR .xlsx : pd.read_excel(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ProductID ProductName     Category  Price\n",
      "0          1      Laptop  Electronics   1000\n",
      "1          2       Chair    Furniture    150\n",
      "2          3        Book   Stationery     20\n"
     ]
    }
   ],
   "source": [
    "# READ DATA FROM JSON FILE INTO DATA FRAMES.\n",
    "\n",
    "\n",
    "df = pd.read_json(r\"C:\\Users\\Pankaj Yadav\\Downloads\\products.json\",encoding = 'latin1')  # encoding character needs to invoke only one time \n",
    "print(df)\n",
    "\n",
    "\n",
    "# Two Types of Encoding.\n",
    "\n",
    "#1 = encoding = \"utf-8\"\n",
    "#2 = encoding = \"latin1\"\n",
    "# Implement those which suits the extension type.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    id                                               name  \\\n",
      "0    1                                    Apple iPhone 12   \n",
      "1    2                                 Samsung Galaxy S21   \n",
      "2    3                                 Sony PlayStation 5   \n",
      "3    4                  LG OLED55CXPUA 55-inch 4K OLED TV   \n",
      "4    5        Bose QuietComfort 35 II Wireless Headphones   \n",
      "5    6                          Fitbit Versa 3 Smartwatch   \n",
      "6    7                             KitchenAid Stand Mixer   \n",
      "7    8                 Dyson V11 Absolute Cordless Vacuum   \n",
      "8    9                         Ninja Foodi Smart XL Grill   \n",
      "9   10                    Canon EOS Rebel T8i DSLR Camera   \n",
      "10  11                                  Apple AirPods Pro   \n",
      "11  12        Bose QuietComfort 35 II Wireless Headphones   \n",
      "12  13                    Fitbit Charge 4 Fitness Tracker   \n",
      "13  14                              Samsung Galaxy Watch3   \n",
      "14  15  Sony WH-1000XM4 Wireless Noise-Cancelling Head...   \n",
      "15  16          Breville Barista Express Espresso Machine   \n",
      "16  17                        Keurig K-Elite Coffee Maker   \n",
      "17  18                     iRobot Roomba i7+ Robot Vacuum   \n",
      "18  19                   Ninja Foodi Digital Air Fry Oven   \n",
      "19  20                   Cuisinart ICE-70 Ice Cream Maker   \n",
      "\n",
      "                                          description    price  \\\n",
      "0   The Apple iPhone 12 features a 6.1-inch Super ...   999.00   \n",
      "1   The Samsung Galaxy S21 features a 6.2-inch Dyn...   799.00   \n",
      "2   The Sony PlayStation 5 features an AMD Zen 2-b...   499.99   \n",
      "3   The LG OLED55CXPUA 55-inch 4K OLED TV features...  1599.99   \n",
      "4   The Bose QuietComfort 35 II Wireless Headphone...   299.00   \n",
      "5   The Fitbit Versa 3 Smartwatch features a built...   229.95   \n",
      "6   The KitchenAid Stand Mixer features a 5-quart ...   399.99   \n",
      "7   The Dyson V11 Absolute Cordless Vacuum feature...   699.99   \n",
      "8   The Ninja Foodi Smart XL Grill features 6-in-1...   279.99   \n",
      "9   The Canon EOS Rebel T8i DSLR Camera features a...   899.00   \n",
      "10  The Apple AirPods Pro feature active noise can...   249.00   \n",
      "11  The Bose QuietComfort 35 II Wireless Headphone...   299.00   \n",
      "12  The Fitbit Charge 4 Fitness Tracker features G...   129.95   \n",
      "13  The Samsung Galaxy Watch3 features a rotating ...   399.99   \n",
      "14  The Sony WH-1000XM4 Wireless Noise-Cancelling ...   349.99   \n",
      "15  The Breville Barista Express Espresso Machine ...   699.95   \n",
      "16  The Keurig K-Elite Coffee Maker features a str...   169.99   \n",
      "17  The iRobot Roomba i7+ Robot Vacuum features au...   799.99   \n",
      "18  The Ninja Foodi Digital Air Fry Oven features ...   209.99   \n",
      "19  The Cuisinart ICE-70 Ice Cream Maker features ...   139.99   \n",
      "\n",
      "           category                                              image  \n",
      "0       Electronics  https://www.apple.com/newsroom/images/product/...  \n",
      "1       Electronics  https://images.samsung.com/is/image/samsung/p6...  \n",
      "2       Electronics  https://www.sony.com/image/44baa604124b770c824...  \n",
      "3       Electronics  https://www.lg.com/us/images/tvs/md07501804/ga...  \n",
      "4       Electronics  https://assets.bose.com/content/dam/Bose_DAM/W...  \n",
      "5       Electronics  https://www.fitbit.com/global/content/dam/fitb...  \n",
      "6    Home & Kitchen  https://www.kitchenaid.com/content/dam/global/...  \n",
      "7   Home Appliances  https://www.dysoncanada.ca/dam/dyson/images/pr...  \n",
      "8    Home & Kitchen  https://www.ninjakitchen.com/medias/Ninja-OP50...  \n",
      "9       Electronics  https://www.canon.com.au/-/media/images/produc...  \n",
      "10      Electronics  https://www.apple.com/v/airpods-pro/b/images/m...  \n",
      "11      Electronics  https://assets.bose.com/content/dam/Bose_DAM/W...  \n",
      "12      Electronics  https://www.fitbit.com/global/content/dam/fitb...  \n",
      "13      Electronics  https://images.samsung.com/is/image/samsung/as...  \n",
      "14      Electronics  https://www.sony.com/image/1cdd6354c4cd21cc4f7...  \n",
      "15   Home & Kitchen  https://www.breville.com/content/dam/breville/...  \n",
      "16   Home & Kitchen  https://www.keurig.com/content/dam/global-ecom...  \n",
      "17   Home & Kitchen  https://store.irobot.com/default/i7-vacuuming-...  \n",
      "18   Home & Kitchen  https://www.ninjakitchen.com/static/img/produc...  \n",
      "19   Home & Kitchen  https://www.cuisinart.com/share/images/product...  \n"
     ]
    }
   ],
   "source": [
    "# One more example:\n",
    "\n",
    "# READ EXISTING DATA FROM JSON FILE INTO DATA FRAMES.\n",
    "\n",
    "df = pd.read_json(r\"C:\\Users\\Pankaj Yadav\\Downloads\\sample_Data.json\")\n",
    "print(df)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      ORDERNUMBER  QUANTITYORDERED  PRICEEACH  ORDERLINENUMBER    SALES  \\\n",
      "0           10107               30      95.70                2  2871.00   \n",
      "1           10121               34      81.35                5  2765.90   \n",
      "2           10134               41      94.74                2  3884.34   \n",
      "3           10145               45      83.26                6  3746.70   \n",
      "4           10159               49     100.00               14  5205.27   \n",
      "...           ...              ...        ...              ...      ...   \n",
      "2818        10350               20     100.00               15  2244.40   \n",
      "2819        10373               29     100.00                1  3978.51   \n",
      "2820        10386               43     100.00                4  5417.57   \n",
      "2821        10397               34      62.24                1  2116.16   \n",
      "2822        10414               47      65.52                9  3079.44   \n",
      "\n",
      "            ORDERDATE    STATUS  QTR_ID  MONTH_ID  YEAR_ID  ...  \\\n",
      "0      2/24/2003 0:00   Shipped       1         2     2003  ...   \n",
      "1       5/7/2003 0:00   Shipped       2         5     2003  ...   \n",
      "2       7/1/2003 0:00   Shipped       3         7     2003  ...   \n",
      "3      8/25/2003 0:00   Shipped       3         8     2003  ...   \n",
      "4     10/10/2003 0:00   Shipped       4        10     2003  ...   \n",
      "...               ...       ...     ...       ...      ...  ...   \n",
      "2818   12/2/2004 0:00   Shipped       4        12     2004  ...   \n",
      "2819   1/31/2005 0:00   Shipped       1         1     2005  ...   \n",
      "2820    3/1/2005 0:00  Resolved       1         3     2005  ...   \n",
      "2821   3/28/2005 0:00   Shipped       1         3     2005  ...   \n",
      "2822    5/6/2005 0:00   On Hold       2         5     2005  ...   \n",
      "\n",
      "                       ADDRESSLINE1  ADDRESSLINE2           CITY STATE  \\\n",
      "0           897 Long Airport Avenue           NaN            NYC    NY   \n",
      "1                59 rue de l'Abbaye           NaN          Reims   NaN   \n",
      "2     27 rue du Colonel Pierre Avia           NaN          Paris   NaN   \n",
      "3                78934 Hillside Dr.           NaN       Pasadena    CA   \n",
      "4                   7734 Strong St.           NaN  San Francisco    CA   \n",
      "...                             ...           ...            ...   ...   \n",
      "2818             C/ Moralzarzal, 86           NaN         Madrid   NaN   \n",
      "2819                    Torikatu 38           NaN           Oulu   NaN   \n",
      "2820             C/ Moralzarzal, 86           NaN         Madrid   NaN   \n",
      "2821          1 rue Alsace-Lorraine           NaN       Toulouse   NaN   \n",
      "2822             8616 Spinnaker Dr.           NaN         Boston    MA   \n",
      "\n",
      "     POSTALCODE  COUNTRY TERRITORY CONTACTLASTNAME CONTACTFIRSTNAME DEALSIZE  \n",
      "0         10022      USA       NaN              Yu             Kwai    Small  \n",
      "1         51100   France      EMEA         Henriot             Paul    Small  \n",
      "2         75508   France      EMEA        Da Cunha           Daniel   Medium  \n",
      "3         90003      USA       NaN           Young            Julie   Medium  \n",
      "4           NaN      USA       NaN           Brown            Julie   Medium  \n",
      "...         ...      ...       ...             ...              ...      ...  \n",
      "2818      28034    Spain      EMEA          Freyre            Diego    Small  \n",
      "2819      90110  Finland      EMEA       Koskitalo           Pirkko   Medium  \n",
      "2820      28034    Spain      EMEA          Freyre            Diego   Medium  \n",
      "2821      31000   France      EMEA          Roulet          Annette    Small  \n",
      "2822      51003      USA       NaN         Yoshido             Juri   Medium  \n",
      "\n",
      "[2823 rows x 25 columns]\n"
     ]
    }
   ],
   "source": [
    "# READ EXISTING DATA OF FILE OF CSV INTO DATA FRAMES:\n",
    "\n",
    "df = pd.read_csv(r\"C:\\Users\\Pankaj Yadav\\Downloads\\sales_data_sample.csv\", encoding = \"latin1\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Row ID        Order ID Order Date  Ship Date       Ship Mode  \\\n",
      "0          1  CA-2016-152156 2016-11-08 2016-11-11    Second Class   \n",
      "1          2  CA-2016-152156 2016-11-08 2016-11-11    Second Class   \n",
      "2          3  CA-2016-138688 2016-06-12 2016-06-16    Second Class   \n",
      "3          4  US-2015-108966 2015-10-11 2015-10-18  Standard Class   \n",
      "4          5  US-2015-108966 2015-10-11 2015-10-18  Standard Class   \n",
      "...      ...             ...        ...        ...             ...   \n",
      "9989    9990  CA-2014-110422 2014-01-21 2014-01-23    Second Class   \n",
      "9990    9991  CA-2017-121258 2017-02-26 2017-03-03  Standard Class   \n",
      "9991    9992  CA-2017-121258 2017-02-26 2017-03-03  Standard Class   \n",
      "9992    9993  CA-2017-121258 2017-02-26 2017-03-03  Standard Class   \n",
      "9993    9994  CA-2017-119914 2017-05-04 2017-05-09    Second Class   \n",
      "\n",
      "     Customer ID     Customer Name    Segment        Country             City  \\\n",
      "0       CG-12520       Claire Gute   Consumer  United States        Henderson   \n",
      "1       CG-12520       Claire Gute   Consumer  United States        Henderson   \n",
      "2       DV-13045   Darrin Van Huff  Corporate  United States      Los Angeles   \n",
      "3       SO-20335    Sean O'Donnell   Consumer  United States  Fort Lauderdale   \n",
      "4       SO-20335    Sean O'Donnell   Consumer  United States  Fort Lauderdale   \n",
      "...          ...               ...        ...            ...              ...   \n",
      "9989    TB-21400  Tom Boeckenhauer   Consumer  United States            Miami   \n",
      "9990    DB-13060       Dave Brooks   Consumer  United States       Costa Mesa   \n",
      "9991    DB-13060       Dave Brooks   Consumer  United States       Costa Mesa   \n",
      "9992    DB-13060       Dave Brooks   Consumer  United States       Costa Mesa   \n",
      "9993    CC-12220      Chris Cortes   Consumer  United States      Westminster   \n",
      "\n",
      "      ... Postal Code  Region       Product ID         Category Sub-Category  \\\n",
      "0     ...       42420   South  FUR-BO-10001798        Furniture    Bookcases   \n",
      "1     ...       42420   South  FUR-CH-10000454        Furniture       Chairs   \n",
      "2     ...       90036    West  OFF-LA-10000240  Office Supplies       Labels   \n",
      "3     ...       33311   South  FUR-TA-10000577        Furniture       Tables   \n",
      "4     ...       33311   South  OFF-ST-10000760  Office Supplies      Storage   \n",
      "...   ...         ...     ...              ...              ...          ...   \n",
      "9989  ...       33180   South  FUR-FU-10001889        Furniture  Furnishings   \n",
      "9990  ...       92627    West  FUR-FU-10000747        Furniture  Furnishings   \n",
      "9991  ...       92627    West  TEC-PH-10003645       Technology       Phones   \n",
      "9992  ...       92627    West  OFF-PA-10004041  Office Supplies        Paper   \n",
      "9993  ...       92683    West  OFF-AP-10002684  Office Supplies   Appliances   \n",
      "\n",
      "                                           Product Name     Sales  Quantity  \\\n",
      "0                     Bush Somerset Collection Bookcase  261.9600         2   \n",
      "1     Hon Deluxe Fabric Upholstered Stacking Chairs,...  731.9400         3   \n",
      "2     Self-Adhesive Address Labels for Typewriters b...   14.6200         2   \n",
      "3         Bretford CR4500 Series Slim Rectangular Table  957.5775         5   \n",
      "4                        Eldon Fold 'N Roll Cart System   22.3680         2   \n",
      "...                                                 ...       ...       ...   \n",
      "9989                             Ultra Door Pull Handle   25.2480         3   \n",
      "9990  Tenex B1-RE Series Chair Mats for Low Pile Car...   91.9600         2   \n",
      "9991                              Aastra 57i VoIP phone  258.5760         2   \n",
      "9992  It's Hot Message Books with Stickers, 2 3/4\" x 5\"   29.6000         4   \n",
      "9993  Acco 7-Outlet Masterpiece Power Center, Wihtou...  243.1600         2   \n",
      "\n",
      "      Discount    Profit  \n",
      "0         0.00   41.9136  \n",
      "1         0.00  219.5820  \n",
      "2         0.00    6.8714  \n",
      "3         0.45 -383.0310  \n",
      "4         0.20    2.5164  \n",
      "...        ...       ...  \n",
      "9989      0.20    4.1028  \n",
      "9990      0.00   15.6332  \n",
      "9991      0.20   19.3932  \n",
      "9992      0.00   13.3200  \n",
      "9993      0.00   72.9480  \n",
      "\n",
      "[9994 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "# READ EXISTING DATA OF FILE OF EXCEL INTO DATA FRAMES:\n",
    "\n",
    "df = pd.read_excel(r\"C:\\Users\\Pankaj Yadav\\Downloads\\SampleSuperstore.xlsx\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ALSO EXPLORE ABOUT HOW TO READ ACCCES DATA OF SPECIFIC EXTENSION IF IT  EXIST ON ANY CLOUD PLATFORNM .  Explore about gcsfs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating/Saving and the Reading the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Name City  Age\n",
      "0        Ram    A   12\n",
      "1      Shyam    B   34\n",
      "2  Ghanshyam    C   56\n"
     ]
    }
   ],
   "source": [
    "# lets create a file first:\n",
    "\n",
    "data = {\n",
    "    \"Name\" : [\"Ram\",\"Shyam\",\"Ghanshyam\"],\n",
    "    \"City\" : [\"A\",\"B\",\"C\"],\n",
    "    \"Age\"  : [12,34,56]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Name City  Age\n",
      "0        Ram    A   12\n",
      "1      Shyam    B   34\n",
      "2  Ghanshyam    C   56\n"
     ]
    }
   ],
   "source": [
    "# Saving that created file:\n",
    "\n",
    "# To save in csv : Use  df.to_csv(\"savedfile.csv\")  here savedfile.csv will be name of saved file in csv remember .csv extension is imp to specify so that it stores in csv format.\n",
    "# To save in json : Use  df.to_json(\"output.json\")  here same rule also applies\n",
    "# To save in excel : Use  df.to_excel(\"output.xlsx\")  here also.\n",
    "\n",
    "# Remember that to_csv, to_excel , to_json are prebuilt methods\n",
    "# Here df is name of created dataframe.\n",
    "# If you wish not to print that idx no 0,1,2,3,4, .. into saved filed simply passs index = False along sied of savedfile name. see now\n",
    "\n",
    "\n",
    "data = {\n",
    "    \n",
    "    \"Name\" : [\"Ram\",\"Shyam\",\"Ghanshyam\"],\n",
    "    \"City\" : [\"A\",\"B\",\"C\"],\n",
    "    \"Age\"  : [12,34,56]\n",
    "\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print(df)\n",
    "\n",
    "df.to_csv(\"savedfile.csv\", index = False)  # see in file due to using index = False it deletes idx nos.\n",
    "\n",
    "df.to_json(\"savedfilejson.json\")  \n",
    " \n",
    "df.to_excel(\"file_excel.xlsx\", index = False)   # To show it in this excel format we required openpyx1 module intallation and imortaing and also we need extension of excel viewer.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So far we read existing file and created then saved file in different format !\n",
    "# Now we will see how to explore data in various process and ways ! Lets Go"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Exploration in Pandas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Why we need to explore data! see following reasons !\n",
    "\n",
    "# 1: To understand data set i.e to get idea idea about no of rows and columnns,their names and types of data types presents there.\n",
    "# 2: To identifying problem and appprocohing their solution.\n",
    "# 3: To get idea about missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Head and Tail method..\n",
    "# These methid gives idea about first and last n rows of data set to figure out orientation and clarity in data set.\n",
    "# This methods will revieves only integer values as prameter.\n",
    "# And remembers bades on numbers of passed integer as paraameter it gives no of firsta nd last row.\n",
    "# If you doest pass any parameter as integer it will by default pass first/last  5 rows.\n",
    "# Its also addups some brief data in first n rows and columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 10 rows of dataframe:\n",
      "    ORDERNUMBER  QUANTITYORDERED  PRICEEACH  ORDERLINENUMBER    SALES  \\\n",
      "0        10107               30      95.70                2  2871.00   \n",
      "1        10121               34      81.35                5  2765.90   \n",
      "2        10134               41      94.74                2  3884.34   \n",
      "3        10145               45      83.26                6  3746.70   \n",
      "4        10159               49     100.00               14  5205.27   \n",
      "5        10168               36      96.66                1  3479.76   \n",
      "6        10180               29      86.13                9  2497.77   \n",
      "7        10188               48     100.00                1  5512.32   \n",
      "8        10201               22      98.57                2  2168.54   \n",
      "9        10211               41     100.00               14  4708.44   \n",
      "\n",
      "         ORDERDATE   STATUS  QTR_ID  MONTH_ID  YEAR_ID  ...  \\\n",
      "0   2/24/2003 0:00  Shipped       1         2     2003  ...   \n",
      "1    5/7/2003 0:00  Shipped       2         5     2003  ...   \n",
      "2    7/1/2003 0:00  Shipped       3         7     2003  ...   \n",
      "3   8/25/2003 0:00  Shipped       3         8     2003  ...   \n",
      "4  10/10/2003 0:00  Shipped       4        10     2003  ...   \n",
      "5  10/28/2003 0:00  Shipped       4        10     2003  ...   \n",
      "6  11/11/2003 0:00  Shipped       4        11     2003  ...   \n",
      "7  11/18/2003 0:00  Shipped       4        11     2003  ...   \n",
      "8   12/1/2003 0:00  Shipped       4        12     2003  ...   \n",
      "9   1/15/2004 0:00  Shipped       1         1     2004  ...   \n",
      "\n",
      "                    ADDRESSLINE1  ADDRESSLINE2           CITY STATE  \\\n",
      "0        897 Long Airport Avenue           NaN            NYC    NY   \n",
      "1             59 rue de l'Abbaye           NaN          Reims   NaN   \n",
      "2  27 rue du Colonel Pierre Avia           NaN          Paris   NaN   \n",
      "3             78934 Hillside Dr.           NaN       Pasadena    CA   \n",
      "4                7734 Strong St.           NaN  San Francisco    CA   \n",
      "5              9408 Furth Circle           NaN     Burlingame    CA   \n",
      "6        184, chausse de Tournai           NaN          Lille   NaN   \n",
      "7    Drammen 121, PR 744 Sentrum           NaN         Bergen   NaN   \n",
      "8      5557 North Pendale Street           NaN  San Francisco    CA   \n",
      "9              25, rue Lauriston           NaN          Paris   NaN   \n",
      "\n",
      "  POSTALCODE COUNTRY TERRITORY CONTACTLASTNAME CONTACTFIRSTNAME DEALSIZE  \n",
      "0      10022     USA       NaN              Yu             Kwai    Small  \n",
      "1      51100  France      EMEA         Henriot             Paul    Small  \n",
      "2      75508  France      EMEA        Da Cunha           Daniel   Medium  \n",
      "3      90003     USA       NaN           Young            Julie   Medium  \n",
      "4        NaN     USA       NaN           Brown            Julie   Medium  \n",
      "5      94217     USA       NaN          Hirano             Juri   Medium  \n",
      "6      59000  France      EMEA           Rance          Martine    Small  \n",
      "7     N 5804  Norway      EMEA          Oeztan           Veysel   Medium  \n",
      "8        NaN     USA       NaN          Murphy            Julie    Small  \n",
      "9      75016  France      EMEA         Perrier        Dominique   Medium  \n",
      "\n",
      "[10 rows x 25 columns]\n",
      "Last 10 rows of dataframe:\n",
      "       ORDERNUMBER  QUANTITYORDERED  PRICEEACH  ORDERLINENUMBER    SALES  \\\n",
      "2815        10315               40      55.69                5  2227.60   \n",
      "2816        10327               37      86.74                4  3209.38   \n",
      "2817        10337               42      97.16                5  4080.72   \n",
      "2818        10350               20     100.00               15  2244.40   \n",
      "2819        10373               29     100.00                1  3978.51   \n",
      "2820        10386               43     100.00                4  5417.57   \n",
      "2821        10397               34      62.24                1  2116.16   \n",
      "2822        10414               47      65.52                9  3079.44   \n",
      "\n",
      "            ORDERDATE    STATUS  QTR_ID  MONTH_ID  YEAR_ID  ...  \\\n",
      "2815  10/29/2004 0:00   Shipped       4        10     2004  ...   \n",
      "2816  11/10/2004 0:00  Resolved       4        11     2004  ...   \n",
      "2817  11/21/2004 0:00   Shipped       4        11     2004  ...   \n",
      "2818   12/2/2004 0:00   Shipped       4        12     2004  ...   \n",
      "2819   1/31/2005 0:00   Shipped       1         1     2005  ...   \n",
      "2820    3/1/2005 0:00  Resolved       1         3     2005  ...   \n",
      "2821   3/28/2005 0:00   Shipped       1         3     2005  ...   \n",
      "2822    5/6/2005 0:00   On Hold       2         5     2005  ...   \n",
      "\n",
      "                      ADDRESSLINE1  ADDRESSLINE2       CITY STATE POSTALCODE  \\\n",
      "2815  67, rue des Cinquante Otages           NaN     Nantes   NaN      44000   \n",
      "2816                  Vinb'ltet 34           NaN  Kobenhavn   NaN       1734   \n",
      "2817              5905 Pompton St.     Suite 750        NYC    NY      10022   \n",
      "2818            C/ Moralzarzal, 86           NaN     Madrid   NaN      28034   \n",
      "2819                   Torikatu 38           NaN       Oulu   NaN      90110   \n",
      "2820            C/ Moralzarzal, 86           NaN     Madrid   NaN      28034   \n",
      "2821         1 rue Alsace-Lorraine           NaN   Toulouse   NaN      31000   \n",
      "2822            8616 Spinnaker Dr.           NaN     Boston    MA      51003   \n",
      "\n",
      "      COUNTRY TERRITORY CONTACTLASTNAME CONTACTFIRSTNAME DEALSIZE  \n",
      "2815   France      EMEA         Labrune           Janine    Small  \n",
      "2816  Denmark      EMEA        Petersen            Jytte   Medium  \n",
      "2817      USA       NaN       Hernandez            Maria   Medium  \n",
      "2818    Spain      EMEA          Freyre            Diego    Small  \n",
      "2819  Finland      EMEA       Koskitalo           Pirkko   Medium  \n",
      "2820    Spain      EMEA          Freyre            Diego   Medium  \n",
      "2821   France      EMEA          Roulet          Annette    Small  \n",
      "2822      USA       NaN         Yoshido             Juri   Medium  \n",
      "\n",
      "[8 rows x 25 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "df = pd.read_csv(r\"C:\\Users\\Pankaj Yadav\\Downloads\\sales_data_sample.csv\", encoding = \"latin1\")\n",
    "\n",
    "\n",
    "first_n_row = df.head(10)\n",
    "last_n_row = df.tail(8)\n",
    "\n",
    "print(\"First 10 rows of dataframe:\\n\",first_n_row)\n",
    "print(\"Last 10 rows of dataframe:\\n\",last_n_row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets explore about data now\n",
    "# Using info() method we will get holistic overview about the data(data frame)!  let see what it gives\n",
    "\n",
    "# Counts no of rows and column.\n",
    "# Columns name.\n",
    "# Data types type\n",
    "# Non null counts\n",
    "# Memory usages of the data frame(i.e it is very useful so that we get idea about memory consumpsion dealing with large data set.)\n",
    "# To get other infos as well.\n",
    "\n",
    "# In simple words info()  gives summarize idea about the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3 entries, 0 to 2\n",
      "Data columns (total 6 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   Name        3 non-null      object\n",
      " 1   City        3 non-null      object\n",
      " 2   Age         3 non-null      int64 \n",
      " 3   Sex         3 non-null      object\n",
      " 4   Section     3 non-null      object\n",
      " 5   Group Code  3 non-null      int64 \n",
      "dtypes: int64(2), object(4)\n",
      "memory usage: 276.0+ bytes\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data = {\n",
    "    \n",
    "    \"Name\" : [\"Ram\",\"Shyam\",\"Ghanshyam\"],\n",
    "    \"City\" : [\"A\",\"B\",\"C\"],\n",
    "    \"Age\"  : [12,34,56],\n",
    "    \"Sex\"  : [\"M\",\"M\",\"F\"],\n",
    "    \"Section\" : [\"A\",\"B\",\"C\"],\n",
    "    \"Group Code\" :[3,5,9]\n",
    "\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print(df.info())\n",
    "\n",
    "#   lets see one more example bsaed on info method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Describe Method(): An powerful method/tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This describe method is very powerful tool/method of pandas used to give summmary of descriptave statistic  for numerical column in your dataframe , Donts worry iT is easy to get just be patient.\n",
    "# Remember one thing this describe method deals with only numerical values (rows and columns of numrical values ), not to values of other data type.\n",
    "\n",
    "# Its gives statistic calculation such as\n",
    "# count, mean, standatrd deviation, min value,max value, 25%,50%,75% in each data set and this done in column wise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descriptive Statistic of Data:\n",
      "              Age        Salary  Experience\n",
      "count   6.000000      6.000000    6.000000\n",
      "mean   27.666667  55833.333333    3.666667\n",
      "std     4.501851   8818.541074    2.160247\n",
      "min    22.000000  45000.000000    1.000000\n",
      "25%    25.250000  50500.000000    2.250000\n",
      "50%    27.000000  55000.000000    3.500000\n",
      "75%    29.500000  59500.000000    4.750000\n",
      "max    35.000000  70000.000000    7.000000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Example 1 of Describe method:\n",
    "\n",
    "data_employee = {\n",
    "    \"Name\": [\"Alice\", \"Bob\", \"Charlie\", \"David\", \"Eva\", \"Frank\"],\n",
    "    \"Age\": [25, 30, 22, 35, 28, 26],\n",
    "    \"City\": [\"New York\", \"Los Angeles\", \"Chicago\", \"Houston\", \"Phoenix\", \"Philadelphia\"],\n",
    "    \"Salary\": [50000, 60000, 45000, 70000, 52000, 58000],\n",
    "    \"Department\": [\"HR\", \"IT\", \"Finance\", \"Marketing\", \"Sales\", \"IT\"],\n",
    "    \"Experience\": [2, 5, 1, 7, 3, 4]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data_employee)\n",
    "\n",
    "# Using Describe Method:\n",
    "\n",
    "Describe_method = df.describe()\n",
    "\n",
    "print(\"Descriptive Statistic of Employees data:\\n\",Describe_method)\n",
    "\n",
    "# Its summarise various statistic and numerical aspects regarding only numerical values in coloumn format.\n",
    "\n",
    "# lets see one more example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descriptive statistic of employees data:\n",
      "        EmployeeID        Age       Salary  Experience   Projects  \\\n",
      "count    10.00000  10.000000     10.00000   10.000000  10.000000   \n",
      "mean    105.50000  28.600000  56800.00000    4.000000   5.900000   \n",
      "std       3.02765   3.864367   7315.12892    1.825742   2.601282   \n",
      "min     101.00000  22.000000  45000.00000    1.000000   2.000000   \n",
      "25%     103.25000  26.250000  52250.00000    3.000000   4.250000   \n",
      "50%     105.50000  28.500000  56500.00000    4.000000   5.500000   \n",
      "75%     107.75000  30.750000  60750.00000    5.000000   7.750000   \n",
      "max     110.00000  35.000000  70000.00000    7.000000  10.000000   \n",
      "\n",
      "       HoursWorkedPerWeek  LeavesTaken  PerformanceScore  \n",
      "count           10.000000    10.000000          10.00000  \n",
      "mean            43.400000     1.300000          86.40000  \n",
      "std              4.273952     0.948683           4.64758  \n",
      "min             35.000000     0.000000          78.00000  \n",
      "25%             41.250000     1.000000          84.25000  \n",
      "50%             43.500000     1.000000          87.50000  \n",
      "75%             45.750000     2.000000          89.75000  \n",
      "max             50.000000     3.000000          92.00000  \n"
     ]
    }
   ],
   "source": [
    "# Example 2 of Describe method:\n",
    "\n",
    "data_company = {\n",
    "    \"EmployeeID\": [101, 102, 103, 104, 105, 106, 107, 108, 109, 110],\n",
    "    \"Age\": [25, 30, 22, 35, 28, 26, 31, 29, 33, 27],\n",
    "    \"Salary\": [50000, 60000, 45000, 70000, 52000, 58000, 64000, 55000, 61000, 53000],\n",
    "    \"Experience\": [2, 5, 1, 7, 3, 4, 6, 4, 5, 3],\n",
    "    \"Projects\": [3, 8, 2, 10, 5, 6, 7, 4, 9, 5],\n",
    "    \"HoursWorkedPerWeek\": [40, 45, 35, 50, 42, 44, 48, 41, 46, 43],\n",
    "    \"LeavesTaken\": [2, 1, 3, 0, 2, 1, 1, 2, 0, 1],\n",
    "    \"Department\": [\"HR\", \"IT\", \"Finance\", \"Marketing\", \"Sales\", \"IT\", \"HR\", \"Marketing\", \"Sales\", \"Finance\"],\n",
    "    \"City\": [\"New York\", \"Los Angeles\", \"Chicago\", \"Houston\", \"Phoenix\", \"Philadelphia\", \"San Diego\", \"Dallas\", \"Austin\", \"San Francisco\"],\n",
    "    \"Gender\": [\"Female\", \"Male\", \"Female\", \"Male\", \"Female\", \"Male\", \"Female\", \"Male\", \"Female\", \"Male\"],\n",
    "    \"Education\": [\"Bachelor's\", \"Master's\", \"Bachelor's\", \"MBA\", \"Bachelor's\", \"Master's\", \"PhD\", \"Bachelor's\", \"Master's\", \"MBA\"],\n",
    "    \"PerformanceScore\": [85, 90, 78, 92, 80, 88, 91, 84, 89, 87]\n",
    "}\n",
    "\n",
    "df2 = pd.DataFrame(data_company)\n",
    "desc_method = df2.describe()\n",
    "\n",
    "print(\"Descriptive statistic of employees data:\\n\", desc_method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now you task is to get aware about all aspect of that descriptive analysis of data set. What they really are  and explore about what is that 25%,50%,75%  and what is standard deviation and what are their practical usages in real world  environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Some Other Advanced Operation on dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COLUMNS AND SHAPE property():\n",
    "\n",
    "# 1: Shape() property gives the pairs of no of rows and no of columns(m,n).\n",
    "# 2: Columns() property gives an index represneting the the columns name od data set.\n",
    "# THEY BOTH ARE PROPERTY NOT METHODS THEY DONT TAKE ANY ARGUMENT LIKE METHODS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual Dataframe :\n",
      "       Name  Age          City  Salary Department  Experience\n",
      "0    Alice   25      New York   50000         HR           2\n",
      "1      Bob   30   Los Angeles   60000         IT           5\n",
      "2  Charlie   22       Chicago   45000    Finance           1\n",
      "3    David   35       Houston   70000  Marketing           7\n",
      "4      Eva   28       Phoenix   52000      Sales           3\n",
      "5    Frank   26  Philadelphia   58000         IT           4\n",
      "\n",
      "Shape of our DataFrame: (6, 6)\n",
      "\n",
      "Columns of our DataFrame: Index(['Name', 'Age', 'City', 'Salary', 'Department', 'Experience'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "data_x = {\n",
    "    \"Name\": [\"Alice\", \"Bob\", \"Charlie\", \"David\", \"Eva\", \"Frank\"],\n",
    "    \"Age\": [25, 30, 22, 35, 28, 26],\n",
    "    \"City\": [\"New York\", \"Los Angeles\", \"Chicago\", \"Houston\", \"Phoenix\", \"Philadelphia\"],\n",
    "    \"Salary\": [50000, 60000, 45000, 70000, 52000, 58000],\n",
    "    \"Department\": [\"HR\", \"IT\", \"Finance\", \"Marketing\", \"Sales\", \"IT\"],\n",
    "    \"Experience\": [2, 5, 1, 7, 3, 4]\n",
    "}\n",
    "\n",
    "df_x = pd.DataFrame(data_x)\n",
    "\n",
    "shape_property = df_x.shape\n",
    "\n",
    "columns_property = df_x.columns\n",
    "\n",
    "\n",
    "print(\"Actual Dataframe :\\n\",df_x)\n",
    "print(\"\\nShape of our DataFrame:\",shape_property)\n",
    "print(\"\\nColumns of our DataFrame:\",  columns_property)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# .shape and .columns makes it easier to:\n",
    "\n",
    "# 1: Understand the dataset quickly/Quick overview.\n",
    "\n",
    "# 2: Identify issues like missing data initally so that that we can manipulate or fix that problem asap.\n",
    "\n",
    "# 3: Data manipulation and feature engineering.\n",
    "\n",
    "# 4: Quick overview of all columns name.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Whenevere we deals with data we must be aware of following things and figures.\n",
    "\n",
    "# 1 : You should know to select specific columns to figure out details so that we can do data manipulation and data analysis and data modification.\n",
    "# 2 : You should know how to filter rows based on cerain condition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In Pandas if we wnat to perform following operation we nedds to do following steps.see\n",
    "\n",
    "# 1 :  To Select specific columns = we may access it via using [] square bracket. we will do it now here\n",
    "# 2 :  To filter rows we =  we may do it via using boolean condition.\n",
    "\n",
    "\n",
    "\n",
    "# Now see what is selecting and filtering columns and how to do it. Before it we will see some facts.\n",
    "\n",
    "\n",
    "\n",
    "#1 : Selecting columns returns you:; a: series(single column fo data) will it return if you want to accces single column of data.\n",
    "#                                    b: Data frame of multiple column if you wish for multiple column data.\n",
    "\n",
    "\n",
    "# 2: Filtering rows under some conditions ; we uses Boolean conditions here.\n",
    "\n",
    "# lets goooooooooooo on next cell.\n",
    "\n",
    "\n",
    "data_company = {\n",
    "    \"EmployeeID\": [101, 102, 103, 104, 105, 106, 107, 108, 109, 110],\n",
    "    \"Age\": [25, 30, 22, 35, 28, 26, 31, 29, 33, 27],\n",
    "    \"Salary\": [50000, 60000, 45000, 70000, 52000, 58000, 64000, 55000, 61000, 53000],\n",
    "    \"Experience\": [2, 5, 1, 7, 3, 4, 6, 4, 5, 3],\n",
    "    \"Projects\": [3, 8, 2, 10, 5, 6, 7, 4, 9, 5],\n",
    "    \"HoursWorkedPerWeek\": [40, 45, 35, 50, 42, 44, 48, 41, 46, 43],\n",
    "    \"LeavesTaken\": [2, 1, 3, 0, 2, 1, 1, 2, 0, 1],\n",
    "    \"Department\": [\"HR\", \"IT\", \"Finance\", \"Marketing\", \"Sales\", \"IT\", \"HR\", \"Marketing\", \"Sales\", \"Finance\"],\n",
    "    \"City\": [\"New York\", \"Los Angeles\", \"Chicago\", \"Houston\", \"Phoenix\", \"Philadelphia\", \"San Diego\", \"Dallas\", \"Austin\", \"San Francisco\"],\n",
    "    \"Gender\": [\"Female\", \"Male\", \"Female\", \"Male\", \"Female\", \"Male\", \"Female\", \"Male\", \"Female\", \"Male\"],\n",
    "    \"Education\": [\"Bachelor's\", \"Master's\", \"Bachelor's\", \"MBA\", \"Bachelor's\", \"Master's\", \"PhD\", \"Bachelor's\", \"Master's\", \"MBA\"],\n",
    "    \"PerformanceScore\": [85, 90, 78, 92, 80, 88, 91, 84, 89, 87]\n",
    "}\n",
    "\n",
    "\n",
    "df = pd.DataFrame(data_company)\n",
    "#print(\"Complete DataFrame:\\n\\n\",df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data of project column;\n",
      "\n",
      " 0     3\n",
      "1     8\n",
      "2     2\n",
      "3    10\n",
      "4     5\n",
      "5     6\n",
      "6     7\n",
      "7     4\n",
      "8     9\n",
      "9     5\n",
      "Name: Projects, dtype: int64\n",
      "\n",
      "Data of Education's column\n",
      "\n",
      " 0    Bachelor's\n",
      "1      Master's\n",
      "2    Bachelor's\n",
      "3           MBA\n",
      "4    Bachelor's\n",
      "5      Master's\n",
      "6           PhD\n",
      "7    Bachelor's\n",
      "8      Master's\n",
      "9           MBA\n",
      "Name: Education, dtype: object\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data_company = {\n",
    "    \"EmployeeID\": [101, 102, 103, 104, 105, 106, 107, 108, 109, 110],\n",
    "    \"Age\": [25, 30, 22, 35, 28, 26, 31, 29, 33, 27],\n",
    "    \"Salary\": [50000, 60000, 45000, 70000, 52000, 58000, 64000, 55000, 61000, 53000],\n",
    "    \"Experience\": [2, 5, 1, 7, 3, 4, 6, 4, 5, 3],\n",
    "    \"Projects\": [3, 8, 2, 10, 5, 6, 7, 4, 9, 5],\n",
    "    \"HoursWorkedPerWeek\": [40, 45, 35, 50, 42, 44, 48, 41, 46, 43],\n",
    "    \"LeavesTaken\": [2, 1, 3, 0, 2, 1, 1, 2, 0, 1],\n",
    "    \"Department\": [\"HR\", \"IT\", \"Finance\", \"Marketing\", \"Sales\", \"IT\", \"HR\", \"Marketing\", \"Sales\", \"Finance\"],\n",
    "    \"City\": [\"New York\", \"Los Angeles\", \"Chicago\", \"Houston\", \"Phoenix\", \"Philadelphia\", \"San Diego\", \"Dallas\", \"Austin\", \"San Francisco\"],\n",
    "    \"Gender\": [\"Female\", \"Male\", \"Female\", \"Male\", \"Female\", \"Male\", \"Female\", \"Male\", \"Female\", \"Male\"],\n",
    "    \"Education\": [\"Bachelor's\", \"Master's\", \"Bachelor's\", \"MBA\", \"Bachelor's\", \"Master's\", \"PhD\", \"Bachelor's\", \"Master's\", \"MBA\"],\n",
    "    \"PerformanceScore\": [85, 90, 78, 92, 80, 88, 91, 84, 89, 87]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data_company)\n",
    "\n",
    "\n",
    "# filtering  single columns : Grab the syntax carefully.\n",
    "\n",
    "\n",
    "column_a = df['Projects']  # To acces use single commas only ' ' not \"\" okay ! here \n",
    "print(\"Data of project column;\\n\\n\",column_a)\n",
    "\n",
    "column_b = df['Education']\n",
    "print(\"\\nData of Education's column\\n\\n\",column_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accessing Multiple Columns:\n",
      "\n",
      "    Gender Department\n",
      "0  Female         HR\n",
      "1    Male         IT\n",
      "2  Female    Finance\n",
      "3    Male  Marketing\n",
      "4  Female      Sales\n",
      "5    Male         IT\n",
      "6  Female         HR\n",
      "7    Male  Marketing\n",
      "8  Female      Sales\n",
      "9    Male    Finance\n",
      "\n",
      "\n",
      "Accesing multiple column:\n",
      "\n",
      "    Gender   Education  Age\n",
      "0  Female  Bachelor's   25\n",
      "1    Male    Master's   30\n",
      "2  Female  Bachelor's   22\n",
      "3    Male         MBA   35\n",
      "4  Female  Bachelor's   28\n",
      "5    Male    Master's   26\n",
      "6  Female         PhD   31\n",
      "7    Male  Bachelor's   29\n",
      "8  Female    Master's   33\n",
      "9    Male         MBA   27\n",
      "\n",
      "\n",
      "Accessing multiple columns:\n",
      "\n",
      "    HoursWorkedPerWeek  Experience  EmployeeID  PerformanceScore\n",
      "0                  40           2         101                85\n",
      "1                  45           5         102                90\n",
      "2                  35           1         103                78\n",
      "3                  50           7         104                92\n",
      "4                  42           3         105                80\n",
      "5                  44           4         106                88\n",
      "6                  48           6         107                91\n",
      "7                  41           4         108                84\n",
      "8                  46           5         109                89\n",
      "9                  43           3         110                87\n"
     ]
    }
   ],
   "source": [
    "# Filtering multiple columns : Whenever you are trying to acces more than one column make sure to use 2 square bracket.and rest synatx is saame and just put column name in single closed aphostrophy ' ' okay. So observe synatx carefully.\n",
    "\n",
    "\n",
    "data_company = {\n",
    "    \"EmployeeID\": [101, 102, 103, 104, 105, 106, 107, 108, 109, 110],\n",
    "    \"Age\": [25, 30, 22, 35, 28, 26, 31, 29, 33, 27],\n",
    "    \"Salary\": [50000, 60000, 45000, 70000, 52000, 58000, 64000, 55000, 61000, 53000],\n",
    "    \"Experience\": [2, 5, 1, 7, 3, 4, 6, 4, 5, 3],\n",
    "    \"Projects\": [3, 8, 2, 10, 5, 6, 7, 4, 9, 5],\n",
    "    \"HoursWorkedPerWeek\": [40, 45, 35, 50, 42, 44, 48, 41, 46, 43],\n",
    "    \"LeavesTaken\": [2, 1, 3, 0, 2, 1, 1, 2, 0, 1],\n",
    "    \"Department\": [\"HR\", \"IT\", \"Finance\", \"Marketing\", \"Sales\", \"IT\", \"HR\", \"Marketing\", \"Sales\", \"Finance\"],\n",
    "    \"City\": [\"New York\", \"Los Angeles\", \"Chicago\", \"Houston\", \"Phoenix\", \"Philadelphia\", \"San Diego\", \"Dallas\", \"Austin\", \"San Francisco\"],\n",
    "    \"Gender\": [\"Female\", \"Male\", \"Female\", \"Male\", \"Female\", \"Male\", \"Female\", \"Male\", \"Female\", \"Male\"],\n",
    "    \"Education\": [\"Bachelor's\", \"Master's\", \"Bachelor's\", \"MBA\", \"Bachelor's\", \"Master's\", \"PhD\", \"Bachelor's\", \"Master's\", \"MBA\"],\n",
    "    \"PerformanceScore\": [85, 90, 78, 92, 80, 88, 91, 84, 89, 87]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data_company)\n",
    "\n",
    "multiplecol_a = df[['Gender','Department']]\n",
    "\n",
    "print(\"Accessing Multiple Columns:\\n\\n\",multiplecol_a)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "multiplecol_b = df[['Gender','Education','Age']]\n",
    "\n",
    "print(\"\\n\\nAccesing multiple column:\\n\\n\",multiplecol_b)\n",
    "\n",
    "\n",
    "multiplecol_c = df[['HoursWorkedPerWeek','Experience','EmployeeID','PerformanceScore']]\n",
    "\n",
    "print(\"\\n\\nAccessing multiple columns:\\n\\n\",multiplecol_c)\n",
    "\n",
    "\n",
    "# Bas thoda syntax format se aware rehna okay!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single conditioned filtered row:\n",
      "\n",
      "    EmployeeID  Age  Salary  Experience  Projects  HoursWorkedPerWeek  \\\n",
      "1         102   30   60000           5         8                  45   \n",
      "3         104   35   70000           7        10                  50   \n",
      "4         105   28   52000           3         5                  42   \n",
      "6         107   31   64000           6         7                  48   \n",
      "7         108   29   55000           4         4                  41   \n",
      "8         109   33   61000           5         9                  46   \n",
      "\n",
      "   LeavesTaken Department         City  Gender   Education  PerformanceScore  \n",
      "1            1         IT  Los Angeles    Male    Master's                90  \n",
      "3            0  Marketing      Houston    Male         MBA                92  \n",
      "4            2      Sales      Phoenix  Female  Bachelor's                80  \n",
      "6            1         HR    San Diego  Female         PhD                91  \n",
      "7            2  Marketing       Dallas    Male  Bachelor's                84  \n",
      "8            0      Sales       Austin  Female    Master's                89  \n",
      "\n",
      " Single Conditioned fileterd row:\n",
      "\n",
      "    EmployeeID  Age  Salary  Experience  Projects  HoursWorkedPerWeek  \\\n",
      "2         103   22   45000           1         2                  35   \n",
      "4         105   28   52000           3         5                  42   \n",
      "7         108   29   55000           4         4                  41   \n",
      "\n",
      "   LeavesTaken Department     City  Gender   Education  PerformanceScore  \n",
      "2            3    Finance  Chicago  Female  Bachelor's                78  \n",
      "4            2      Sales  Phoenix  Female  Bachelor's                80  \n",
      "7            2  Marketing   Dallas    Male  Bachelor's                84  \n"
     ]
    }
   ],
   "source": [
    "# Now we will access that rows with conditions. Lets go!\n",
    "\n",
    "\n",
    "data_company = {\n",
    "\n",
    "    \"EmployeeID\": [101, 102, 103, 104, 105, 106, 107, 108, 109, 110],\n",
    "    \"Age\": [25, 30, 22, 35, 28, 26, 31, 29, 33, 27],\n",
    "    \"Salary\": [50000, 60000, 45000, 70000, 52000, 58000, 64000, 55000, 61000, 53000],\n",
    "    \"Experience\": [2, 5, 1, 7, 3, 4, 6, 4, 5, 3],\n",
    "    \"Projects\": [3, 8, 2, 10, 5, 6, 7, 4, 9, 5],\n",
    "    \"HoursWorkedPerWeek\": [40, 45, 35, 50, 42, 44, 48, 41, 46, 43],\n",
    "    \"LeavesTaken\": [2, 1, 3, 0, 2, 1, 1, 2, 0, 1],\n",
    "    \"Department\": [\"HR\", \"IT\", \"Finance\", \"Marketing\", \"Sales\", \"IT\", \"HR\", \"Marketing\", \"Sales\", \"Finance\"],\n",
    "    \"City\": [\"New York\", \"Los Angeles\", \"Chicago\", \"Houston\", \"Phoenix\", \"Philadelphia\", \"San Diego\", \"Dallas\", \"Austin\", \"San Francisco\"],\n",
    "    \"Gender\": [\"Female\", \"Male\", \"Female\", \"Male\", \"Female\", \"Male\", \"Female\", \"Male\", \"Female\", \"Male\"],\n",
    "    \"Education\": [\"Bachelor's\", \"Master's\", \"Bachelor's\", \"MBA\", \"Bachelor's\", \"Master's\", \"PhD\", \"Bachelor's\", \"Master's\", \"MBA\"],\n",
    "    \"PerformanceScore\": [85, 90, 78, 92, 80, 88, 91, 84, 89, 87]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data_company)\n",
    "\n",
    "\n",
    "# Lets Accessing Rows with single condition: see syntax carefully.\n",
    "\n",
    "filtered_row1 = df[df['Age'] > 27]\n",
    "print(\"Single conditioned filtered row:\\n\\n\",filtered_row1)\n",
    "\n",
    " # Its willl return all those columns data where in row age is > 27.lets see one more case.\n",
    "\n",
    "filtered_row2 = df[df['PerformanceScore']<85]\n",
    "print(\"\\n Single Conditioned fileterd row:\\n\\n\", filtered_row2)\n",
    "\n",
    " # Its willl return all those columns data where in row where performancescore is < 27.lets see one more case.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accesing row with multiple  with(&):\n",
      "\n",
      "    EmployeeID  Age  Salary  Experience  Projects  HoursWorkedPerWeek  \\\n",
      "3         104   35   70000           7        10                  50   \n",
      "\n",
      "   LeavesTaken Department     City Gender Education  PerformanceScore  \n",
      "3            0  Marketing  Houston   Male       MBA                92  \n",
      "\n",
      "\n",
      "Accesing row with myltiple conditions with(OR) :\n",
      "\n",
      "    EmployeeID  Age  Salary  Experience  Projects  HoursWorkedPerWeek  \\\n",
      "2         103   22   45000           1         2                  35   \n",
      "3         104   35   70000           7        10                  50   \n",
      "4         105   28   52000           3         5                  42   \n",
      "6         107   31   64000           6         7                  48   \n",
      "7         108   29   55000           4         4                  41   \n",
      "\n",
      "   LeavesTaken Department       City  Gender   Education  PerformanceScore  \n",
      "2            3    Finance    Chicago  Female  Bachelor's                78  \n",
      "3            0  Marketing    Houston    Male         MBA                92  \n",
      "4            2      Sales    Phoenix  Female  Bachelor's                80  \n",
      "6            1         HR  San Diego  Female         PhD                91  \n",
      "7            2  Marketing     Dallas    Male  Bachelor's                84  \n",
      "\n",
      "\n",
      "Filetering rows with multiple condition with(NOT):\n",
      "\n",
      "    EmployeeID  Age  Salary  Experience  Projects  HoursWorkedPerWeek  \\\n",
      "1         102   30   60000           5         8                  45   \n",
      "3         104   35   70000           7        10                  50   \n",
      "5         106   26   58000           4         6                  44   \n",
      "7         108   29   55000           4         4                  41   \n",
      "9         110   27   53000           3         5                  43   \n",
      "\n",
      "   LeavesTaken Department           City Gender   Education  PerformanceScore  \n",
      "1            1         IT    Los Angeles   Male    Master's                90  \n",
      "3            0  Marketing        Houston   Male         MBA                92  \n",
      "5            1         IT   Philadelphia   Male    Master's                88  \n",
      "7            2  Marketing         Dallas   Male  Bachelor's                84  \n",
      "9            1    Finance  San Francisco   Male         MBA                87  \n",
      "\n",
      "\n",
      "Filetering rows with multiple condition with(NOT):\n",
      "\n",
      "    EmployeeID  Age  Salary  Experience  Projects  HoursWorkedPerWeek  \\\n",
      "0         101   25   50000           2         3                  40   \n",
      "1         102   30   60000           5         8                  45   \n",
      "2         103   22   45000           1         2                  35   \n",
      "3         104   35   70000           7        10                  50   \n",
      "4         105   28   52000           3         5                  42   \n",
      "5         106   26   58000           4         6                  44   \n",
      "6         107   31   64000           6         7                  48   \n",
      "7         108   29   55000           4         4                  41   \n",
      "8         109   33   61000           5         9                  46   \n",
      "9         110   27   53000           3         5                  43   \n",
      "\n",
      "   LeavesTaken Department           City  Gender   Education  PerformanceScore  \n",
      "0            2         HR       New York  Female  Bachelor's                85  \n",
      "1            1         IT    Los Angeles    Male    Master's                90  \n",
      "2            3    Finance        Chicago  Female  Bachelor's                78  \n",
      "3            0  Marketing        Houston    Male         MBA                92  \n",
      "4            2      Sales        Phoenix  Female  Bachelor's                80  \n",
      "5            1         IT   Philadelphia    Male    Master's                88  \n",
      "6            1         HR      San Diego  Female         PhD                91  \n",
      "7            2  Marketing         Dallas    Male  Bachelor's                84  \n",
      "8            0      Sales         Austin  Female    Master's                89  \n",
      "9            1    Finance  San Francisco    Male         MBA                87  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "data_company = {\n",
    "\n",
    "    \"EmployeeID\": [101, 102, 103, 104, 105, 106, 107, 108, 109, 110],\n",
    "    \"Age\": [25, 30, 22, 35, 28, 26, 31, 29, 33, 27],\n",
    "    \"Salary\": [50000, 60000, 45000, 70000, 52000, 58000, 64000, 55000, 61000, 53000],\n",
    "    \"Experience\": [2, 5, 1, 7, 3, 4, 6, 4, 5, 3],\n",
    "    \"Projects\": [3, 8, 2, 10, 5, 6, 7, 4, 9, 5],\n",
    "    \"HoursWorkedPerWeek\": [40, 45, 35, 50, 42, 44, 48, 41, 46, 43],\n",
    "    \"LeavesTaken\": [2, 1, 3, 0, 2, 1, 1, 2, 0, 1],\n",
    "    \"Department\": [\"HR\", \"IT\", \"Finance\", \"Marketing\", \"Sales\", \"IT\", \"HR\", \"Marketing\", \"Sales\", \"Finance\"],\n",
    "    \"City\": [\"New York\", \"Los Angeles\", \"Chicago\", \"Houston\", \"Phoenix\", \"Philadelphia\", \"San Diego\", \"Dallas\", \"Austin\", \"San Francisco\"],\n",
    "    \"Gender\": [\"Female\", \"Male\", \"Female\", \"Male\", \"Female\", \"Male\", \"Female\", \"Male\", \"Female\", \"Male\"],\n",
    "    \"Education\": [\"Bachelor's\", \"Master's\", \"Bachelor's\", \"MBA\", \"Bachelor's\", \"Master's\", \"PhD\", \"Bachelor's\", \"Master's\", \"MBA\"],\n",
    "    \"PerformanceScore\": [85, 90, 78, 92, 80, 88, 91, 84, 89, 87]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data_company)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Filetering rows with multiple condition. grab syntax carefull here insted of using 2 square bracket we use one [] and within it one () bracket where we specify conditions within single close aphostrophy.\n",
    "\n",
    "#You can combine multiple conditions using:\n",
    "\n",
    "# 1:  & (AND)  both conditions must be true.\n",
    "\n",
    "# 2:| (OR)  at least one condition must be true.\n",
    "\n",
    "# 3: ~ (NOT)  to negate a condition. lets see!\n",
    "\n",
    "# Here syntax is somewhat complex so we comfortable with it! via intense practice.\n",
    "\n",
    "# with (&) condition.\n",
    "\n",
    "filtered_row_a = df[(df['Salary']>65000) & (df['Gender'] == \"Male\")]\n",
    "print(\"Accesing row with multiple  with(&):\\n\\n\",filtered_row_a)\n",
    "\n",
    "\n",
    "# with OR(|) condition.\n",
    "\n",
    "filtered_row_b = df[(df['Experience']> 5) |(df['PerformanceScore']<85)]\n",
    "print(\"\\n\\nAccesing row with myltiple conditions with(OR) :\\n\\n\",filtered_row_b)\n",
    "\n",
    "\n",
    "\n",
    "# with Not(~) condition.\n",
    "\n",
    "filtered_row_c = df[~(df['Gender'] == \"Female\")]\n",
    "fileterd_row_d = df[~(df['Salary']>70000)]\n",
    "\n",
    "\n",
    "print(\"\\n\\nFiletering rows with multiple condition with(NOT):\\n\\n\",filtered_row_c)\n",
    "print(\"\\n\\nFiletering rows with multiple condition with(NOT):\\n\\n\",fileterd_row_d)\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "1stVENV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
